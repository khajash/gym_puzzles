# Easiest to copy this over to sweep when running in wandb
program: train.py
method: bayes
metric:
  goal: maximize
  name: rollout/ep_rew_mean
parameters:
  alg_params.learning_rate:
    max: 0.001
    min: 0.00001
    distribution: uniform
  alg_params.clip_range:
    max: 0.4
    min: 0.1
    distribution: uniform
  alg_params.batch_size:
    values: [64, 128, 256, 512]
    distribution: categorical
  alg_params.n_epochs:
    max: 20
    min: 5
    distribution: int_uniform
  alg_params.ent_coef:
    max: 0.02
    min: 0.005
    distribution: uniform
  alg_params.n_steps:
    values: [512, 1024, 2048, 4096]
    distribution: categorical
  policy_kwargs:
    values:
      - "{'net_arch': [256, 256]}"
      - "{'net_arch': [128, 128]}"
    distribution: categorical
  max_grad_norm:
    max: 1
    min: 0.25
    distribution: uniform
  vf_coef:
    max: 1
    min: 0.25
    distribution: uniform
  n_envs:
    max: 8
    min: 4
    distribution: int_uniform
early_terminate:
  type: hyperband
  s: 2
  eta: 3
  max_iter: 50